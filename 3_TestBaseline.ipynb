{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#SBATCH --job-name=PSNN\n",
    "#SBATCH --error=%x.%j.err\n",
    "#SBATCH --output=%x.%j.out\n",
    "#SBATCH --mail-user=hzhao@teco.edu\n",
    "#SBATCH --export=ALL\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --partition=sdil\n",
    "#SBATCH --gres=gpu:1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), 'utils'))\n",
    "from configuration import *\n",
    "import torch\n",
    "import pprint\n",
    "from utils import *\n",
    "import BaselineModels as B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "args.task = 'temporized'\n",
    "args.SEED = 1\n",
    "args.metric = 'acc'\n",
    "args.lnc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network on device: cuda.\n"
     ]
    }
   ],
   "source": [
    "args = FormulateArgs(args)\n",
    "print(f'Training network on device: {args.DEVICE}.')\n",
    "MakeFolder(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N_class': 2,\n",
      " 'N_feature': 6,\n",
      " 'N_test': 25,\n",
      " 'N_time': 32,\n",
      " 'N_train': 70,\n",
      " 'N_valid': 23,\n",
      " 'dataname': 'acuteinflammation'}\n"
     ]
    }
   ],
   "source": [
    "train_loader, datainfo = GetDataLoader(args, 'train')\n",
    "valid_loader, datainfo = GetDataLoader(args, 'valid')\n",
    "test_loader, datainfo = GetDataLoader(args, 'test')\n",
    "pprint.pprint(datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training setup: baseline_model_SNN_data_acuteinflammation_seed_1.model2.\n"
     ]
    }
   ],
   "source": [
    "SetSeed(args.SEED)\n",
    "setup = f\"baseline_model_SNN_data_{datainfo['dataname']}_seed_{args.SEED}.model2\"\n",
    "print(f'Training setup: {setup}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msglogger = GetMessageLogger(args, setup)\n",
    "msglogger.info(f'Training network on device: {args.DEVICE}.')\n",
    "msglogger.info(f'Training setup: {setup}.')\n",
    "msglogger.info(datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topology = [datainfo['N_feature']] + args.hidden + [datainfo['N_class']]\n",
    "msglogger.info(f'Topology of the network: {topology}.')\n",
    "\n",
    "mlp = B.mlp(args, topology).to(args.DEVICE)\n",
    "lstm = B.lstm(args, datainfo['N_feature'], datainfo['N_class']).to(args.DEVICE)\n",
    "pnn = B.pNN(topology, args).to(args.DEVICE)\n",
    "snn = B.SpikingNeuralNetwork(args, topology).to(args.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta\n",
      "threshold\n",
      "model.MAC0.weight\n",
      "model.MAC1.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, p in snn.named_parameters():\n",
    "    print(n)\n",
    "len(snn.GetParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation.eta\n",
      "model.0-th pLayer.weight\n",
      "model.0-th pLayer.bias\n",
      "model.1-th pLayer.weight\n",
      "model.1-th pLayer.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, p in mlp.named_parameters():\n",
    "    print(n)\n",
    "len(mlp.GetParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.activation.eta\n",
      "rnn.sigmoid.eta\n",
      "rnn.lstm_cell.i2h.weight\n",
      "rnn.lstm_cell.i2h.bias\n",
      "rnn.lstm_cell.h2h.weight\n",
      "rnn.lstm_cell.h2h.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, p in lstm.named_parameters():\n",
    "    print(n)\n",
    "len(lstm.GetParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act.rt_\n",
      "act.eta_estimator.0-MAC.weight\n",
      "act.eta_estimator.0-MAC.bias\n",
      "act.eta_estimator.0-ACT.weight\n",
      "act.eta_estimator.1-MAC.weight\n",
      "act.eta_estimator.1-MAC.bias\n",
      "act.eta_estimator.1-ACT.weight\n",
      "act.eta_estimator.2-MAC.weight\n",
      "act.eta_estimator.2-MAC.bias\n",
      "act.eta_estimator.2-ACT.weight\n",
      "act.eta_estimator.3-MAC.weight\n",
      "act.eta_estimator.3-MAC.bias\n",
      "act.eta_estimator.3-ACT.weight\n",
      "act.eta_estimator.4-MAC.weight\n",
      "act.eta_estimator.4-MAC.bias\n",
      "act.eta_estimator.4-ACT.weight\n",
      "act.eta_estimator.5-MAC.weight\n",
      "act.eta_estimator.5-MAC.bias\n",
      "act.eta_estimator.5-ACT.weight\n",
      "act.eta_estimator.6-MAC.weight\n",
      "act.eta_estimator.6-MAC.bias\n",
      "act.eta_estimator.6-ACT.weight\n",
      "act.eta_estimator.7-MAC.weight\n",
      "act.eta_estimator.7-MAC.bias\n",
      "act.eta_estimator.7-ACT.weight\n",
      "act.eta_estimator.8-MAC.weight\n",
      "act.eta_estimator.8-MAC.bias\n",
      "act.eta_estimator.8-ACT.weight\n",
      "act.eta_estimator.9-MAC.weight\n",
      "act.eta_estimator.9-MAC.bias\n",
      "act.eta_estimator.9-ACT.weight\n",
      "act.eta_estimator.10-MAC.weight\n",
      "act.eta_estimator.10-MAC.bias\n",
      "act.eta_estimator.10-ACT.weight\n",
      "act.eta_estimator.11-MAC.weight\n",
      "act.eta_estimator.11-MAC.bias\n",
      "act.eta_estimator.11-ACT.weight\n",
      "act.eta_estimator.12-MAC.weight\n",
      "act.eta_estimator.12-MAC.bias\n",
      "act.eta_estimator.12-ACT.weight\n",
      "act.eta_estimator.13-MAC.weight\n",
      "act.eta_estimator.13-MAC.bias\n",
      "act.eta_estimator.13-ACT.weight\n",
      "act.power_estimator.0-MAC.weight\n",
      "act.power_estimator.0-MAC.bias\n",
      "act.power_estimator.0-ACT.weight\n",
      "act.power_estimator.1-MAC.weight\n",
      "act.power_estimator.1-MAC.bias\n",
      "act.power_estimator.1-ACT.weight\n",
      "act.power_estimator.2-MAC.weight\n",
      "act.power_estimator.2-MAC.bias\n",
      "act.power_estimator.2-ACT.weight\n",
      "act.power_estimator.3-MAC.weight\n",
      "act.power_estimator.3-MAC.bias\n",
      "act.power_estimator.3-ACT.weight\n",
      "act.power_estimator.4-MAC.weight\n",
      "act.power_estimator.4-MAC.bias\n",
      "act.power_estimator.4-ACT.weight\n",
      "act.power_estimator.5-MAC.weight\n",
      "act.power_estimator.5-MAC.bias\n",
      "act.power_estimator.5-ACT.weight\n",
      "act.power_estimator.6-MAC.weight\n",
      "act.power_estimator.6-MAC.bias\n",
      "act.power_estimator.6-ACT.weight\n",
      "act.power_estimator.7-MAC.weight\n",
      "act.power_estimator.7-MAC.bias\n",
      "act.power_estimator.7-ACT.weight\n",
      "act.power_estimator.8-MAC.weight\n",
      "act.power_estimator.8-MAC.bias\n",
      "act.power_estimator.8-ACT.weight\n",
      "act.power_estimator.9-MAC.weight\n",
      "act.power_estimator.9-MAC.bias\n",
      "act.power_estimator.9-ACT.weight\n",
      "act.power_estimator.10-MAC.weight\n",
      "act.power_estimator.10-MAC.bias\n",
      "act.power_estimator.10-ACT.weight\n",
      "act.power_estimator.11-MAC.weight\n",
      "act.power_estimator.11-MAC.bias\n",
      "act.power_estimator.11-ACT.weight\n",
      "act.power_estimator.12-MAC.weight\n",
      "act.power_estimator.12-MAC.bias\n",
      "act.power_estimator.12-ACT.weight\n",
      "act.power_estimator.13-MAC.weight\n",
      "act.power_estimator.13-MAC.bias\n",
      "act.power_estimator.13-ACT.weight\n",
      "inv.rt_\n",
      "inv.eta_estimator.0-MAC.weight\n",
      "inv.eta_estimator.0-MAC.bias\n",
      "inv.eta_estimator.0-ACT.weight\n",
      "inv.eta_estimator.1-MAC.weight\n",
      "inv.eta_estimator.1-MAC.bias\n",
      "inv.eta_estimator.1-ACT.weight\n",
      "inv.eta_estimator.2-MAC.weight\n",
      "inv.eta_estimator.2-MAC.bias\n",
      "inv.eta_estimator.2-ACT.weight\n",
      "inv.eta_estimator.3-MAC.weight\n",
      "inv.eta_estimator.3-MAC.bias\n",
      "inv.eta_estimator.3-ACT.weight\n",
      "inv.eta_estimator.4-MAC.weight\n",
      "inv.eta_estimator.4-MAC.bias\n",
      "inv.eta_estimator.4-ACT.weight\n",
      "inv.eta_estimator.5-MAC.weight\n",
      "inv.eta_estimator.5-MAC.bias\n",
      "inv.eta_estimator.5-ACT.weight\n",
      "inv.eta_estimator.6-MAC.weight\n",
      "inv.eta_estimator.6-MAC.bias\n",
      "inv.eta_estimator.6-ACT.weight\n",
      "inv.eta_estimator.7-MAC.weight\n",
      "inv.eta_estimator.7-MAC.bias\n",
      "inv.eta_estimator.7-ACT.weight\n",
      "inv.eta_estimator.8-MAC.weight\n",
      "inv.eta_estimator.8-MAC.bias\n",
      "inv.eta_estimator.8-ACT.weight\n",
      "inv.eta_estimator.9-MAC.weight\n",
      "inv.eta_estimator.9-MAC.bias\n",
      "inv.eta_estimator.9-ACT.weight\n",
      "inv.eta_estimator.10-MAC.weight\n",
      "inv.eta_estimator.10-MAC.bias\n",
      "inv.eta_estimator.10-ACT.weight\n",
      "inv.eta_estimator.11-MAC.weight\n",
      "inv.eta_estimator.11-MAC.bias\n",
      "inv.eta_estimator.11-ACT.weight\n",
      "inv.eta_estimator.12-MAC.weight\n",
      "inv.eta_estimator.12-MAC.bias\n",
      "inv.eta_estimator.12-ACT.weight\n",
      "inv.eta_estimator.13-MAC.weight\n",
      "inv.eta_estimator.13-MAC.bias\n",
      "inv.eta_estimator.13-ACT.weight\n",
      "inv.power_estimator.0-MAC.weight\n",
      "inv.power_estimator.0-MAC.bias\n",
      "inv.power_estimator.0-ACT.weight\n",
      "inv.power_estimator.1-MAC.weight\n",
      "inv.power_estimator.1-MAC.bias\n",
      "inv.power_estimator.1-ACT.weight\n",
      "inv.power_estimator.2-MAC.weight\n",
      "inv.power_estimator.2-MAC.bias\n",
      "inv.power_estimator.2-ACT.weight\n",
      "inv.power_estimator.3-MAC.weight\n",
      "inv.power_estimator.3-MAC.bias\n",
      "inv.power_estimator.3-ACT.weight\n",
      "inv.power_estimator.4-MAC.weight\n",
      "inv.power_estimator.4-MAC.bias\n",
      "inv.power_estimator.4-ACT.weight\n",
      "inv.power_estimator.5-MAC.weight\n",
      "inv.power_estimator.5-MAC.bias\n",
      "inv.power_estimator.5-ACT.weight\n",
      "inv.power_estimator.6-MAC.weight\n",
      "inv.power_estimator.6-MAC.bias\n",
      "inv.power_estimator.6-ACT.weight\n",
      "inv.power_estimator.7-MAC.weight\n",
      "inv.power_estimator.7-MAC.bias\n",
      "inv.power_estimator.7-ACT.weight\n",
      "inv.power_estimator.8-MAC.weight\n",
      "inv.power_estimator.8-MAC.bias\n",
      "inv.power_estimator.8-ACT.weight\n",
      "inv.power_estimator.9-MAC.weight\n",
      "inv.power_estimator.9-MAC.bias\n",
      "inv.power_estimator.9-ACT.weight\n",
      "inv.power_estimator.10-MAC.weight\n",
      "inv.power_estimator.10-MAC.bias\n",
      "inv.power_estimator.10-ACT.weight\n",
      "inv.power_estimator.11-MAC.weight\n",
      "inv.power_estimator.11-MAC.bias\n",
      "inv.power_estimator.11-ACT.weight\n",
      "inv.power_estimator.12-MAC.weight\n",
      "inv.power_estimator.12-MAC.bias\n",
      "inv.power_estimator.12-ACT.weight\n",
      "model.0-th pLayer.theta_\n",
      "model.1-th pLayer.theta_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, p in pnn.named_parameters():\n",
    "    print(n)\n",
    "len(pnn.GetParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a, b = snn(x)\n",
    "b.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight tensor([[ 4.7734e-01,  8.0344e+00, -1.6130e+03],\n",
      "        [ 8.4351e-02,  4.4608e-01, -4.1365e+02],\n",
      "        [ 5.8983e-01,  1.2794e+01, -1.7606e+03],\n",
      "        [ 7.4504e-01,  4.5500e+00, -3.5763e+03],\n",
      "        [ 4.3930e-01,  1.3040e+00, -1.7630e+03],\n",
      "        [ 3.9155e-01,  4.0067e+00, -2.7251e+03],\n",
      "        [ 1.2602e+00,  1.7402e+01, -3.6078e+03]], device='cuda:0')\n",
      "weight tensor([[    0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000],\n",
      "        [  684.3574,   684.3574],\n",
      "        [22224.3848, 22224.3848]], device='cuda:0')\n",
      "beta tensor(-896.5642, device='cuda:0')\n",
      "threshold tensor(345.7404, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for n, p in snn.getAllNamedParameters():\n",
    "    print(n, p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0690,  0.0418, -0.0213],\n",
       "         [-0.0840, -0.0420, -0.0964],\n",
       "         [ 0.0142, -0.0164, -0.0358],\n",
       "         [-0.0059, -0.2492,  0.0242],\n",
       "         [ 0.0288,  0.0103,  0.1100],\n",
       "         [-0.0342,  0.0947,  0.0622],\n",
       "         [-0.0448, -0.0286,  0.0388]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1595, -0.1528],\n",
       "         [ 0.1016, -0.0202],\n",
       "         [-0.1286,  0.0823],\n",
       "         [-0.0610, -0.1296]], device='cuda:0', requires_grad=True),\n",
       " tensor(2.9444, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       " tensor(1., device='cuda:0', grad_fn=<CopyBackwards>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn.GetParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can't optimize a non-leaf Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetParam\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnn/lib/python3.9/site-packages/torch/optim/adam.py:48\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(weight_decay))\n\u001b[1;32m     46\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     47\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnn/lib/python3.9/site-packages/torch/optim/optimizer.py:54\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     51\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnn/lib/python3.9/site-packages/torch/optim/optimizer.py:257\u001b[0m, in \u001b[0;36mOptimizer.add_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer can only optimize Tensors, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut one of the params is \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtypename(param))\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m param\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[0;32m--> 257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt optimize a non-leaf Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, default \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m required \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_group:\n",
      "\u001b[0;31mValueError\u001b[0m: can't optimize a non-leaf Tensor"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(snn.GetParam(), lr=args.LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 6, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy = lstm(x)\n",
    "yyy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:      0 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   0 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      1 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   1 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      2 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   2 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      3 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   3 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      4 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   4 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      5 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   5 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      6 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   6 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      7 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   7 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      8 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   8 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:      9 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:   9 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     10 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  10 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     11 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  11 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     12 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  12 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     13 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  13 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     14 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  14 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     15 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  15 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     16 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  16 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     17 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  17 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     18 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  18 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     19 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  19 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     20 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  20 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     21 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  21 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     22 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  22 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     23 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  23 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     24 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  24 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     25 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  25 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n",
      "| Epoch:     26 | Train loss: 6.7707e-01 | Valid loss: 6.8251e-01 | Train acc: 0.4857 | Valid acc: 0.3913 | patience:  26 | lr: 0.1 | Epoch time: 0.1 | Power: 0.00e+00 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(f'{args.savepath}/{setup}'):\n",
    "    print(f'{setup} exists, skip this training.')\n",
    "    msglogger.info('Training was already finished.')\n",
    "else:\n",
    "    topology = [datainfo['N_feature']] + args.hidden + [datainfo['N_class']]\n",
    "    msglogger.info(f'Topology of the network: {topology}.')\n",
    "\n",
    "    \n",
    "    lossfunction = B.CELOSS().to(args.DEVICE)\n",
    "    optimizer = torch.optim.Adam(snn.parameters(), lr=args.LR)\n",
    "\n",
    "    if args.PROGRESSIVE:\n",
    "        lstm, best = train_pnn_progressive(lstm, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "    else:\n",
    "        lstm, best = train_pnn(lstm, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "\n",
    "    if best:\n",
    "        if not os.path.exists(f'{args.savepath}/'):\n",
    "            os.makedirs(f'{args.savepath}/')\n",
    "        torch.save(lstm, f'{args.savepath}/{setup}')\n",
    "        msglogger.info('Training if finished.')\n",
    "    else:\n",
    "        msglogger.warning('Time out, further training is necessary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pNN",
   "language": "python",
   "name": "pnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
