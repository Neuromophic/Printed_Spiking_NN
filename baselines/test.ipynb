{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#SBATCH --job-name=SNNBase\n",
    "#SBATCH --error=%x.%j.err\n",
    "#SBATCH --mail-user=hzhao@teco.edu\n",
    "#SBATCH --export=ALL\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --partition=sdil\n",
    "#SBATCH --gres=gpu:1\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from pprint import pprint\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "import training as T\n",
    "import snntorch as snn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "ds_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: ArrowHead, N_train: 126, N_valid: 42, N_test: 43, N_class: 3, N_feature: 251, N_channel: 1, N_length: 251\n"
     ]
    }
   ],
   "source": [
    "datasets = os.listdir('../ts_datasets/')\n",
    "datasets = [dataset for dataset in datasets if dataset.endswith('.tsds')]\n",
    "datasets.sort()\n",
    "\n",
    "dataset = datasets[ds_idx]\n",
    "package = torch.load(f'../ts_datasets/{dataset}')\n",
    "\n",
    "name = package['name']\n",
    "\n",
    "N_train = package['N_train']\n",
    "N_valid = package['N_valid']\n",
    "N_test = package['N_test']\n",
    "\n",
    "N_class = package['N_class']\n",
    "\n",
    "N_channel = package['N_channel']\n",
    "N_length = package['N_length']\n",
    "\n",
    "N_feature = N_channel * N_length\n",
    "\n",
    "print(f'dataset: {name}, N_train: {N_train}, N_valid: {N_valid}, N_test: {N_test}, N_class: {N_class}, N_feature: {N_feature}, N_channel: {N_channel}, N_length: {N_length}')\n",
    "\n",
    "X_train = package['X_train']\n",
    "X_valid = package['X_valid']\n",
    "X_test = package['X_test']\n",
    "\n",
    "y_train = package['Y_train']\n",
    "y_valid = package['Y_valid']\n",
    "y_test = package['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Network\n",
    "class SNN(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize layers\n",
    "        # self.lif1 = snn.Leaky(beta=torch.rand([]), learn_beta=True,\n",
    "        #                       threshold=torch.rand([]), learn_threshold=True)\n",
    "        self.fc1 = torch.nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif2 = snn.Leaky(beta=torch.rand([]), learn_beta=True,\n",
    "                              threshold=torch.rand([]), learn_threshold=True)\n",
    "        self.fc2 = torch.nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif3 = snn.Leaky(beta=torch.rand([]), learn_beta=True,\n",
    "                              threshold=torch.rand([]), learn_threshold=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_steps = x.shape[2]\n",
    "\n",
    "        # mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        spk_rec = []  # Record the output trace of spikes\n",
    "        mem_rec = []  # Record the output trace of membrane potential\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # spk1, mem1 = self.lif1(x[:,:,step], mem1)\n",
    "            curl1 = self.fc1(x[:,:,step])\n",
    "            spk2, mem2 = self.lif2(curl1, mem2)\n",
    "            curl2 = self.fc2(spk2)\n",
    "            spk3, mem3 = self.lif3(curl2, mem3)\n",
    "            spk_rec.append(spk3)\n",
    "            mem_rec.append(mem3)\n",
    "        self.spikes = torch.stack(spk_rec, dim=1)\n",
    "        self.mem = torch.stack(mem_rec, dim=1)\n",
    "        return self.mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SNN(N_channel, 3, N_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = T.SNNLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:        0 | train loss: 1.59275e+01 | valid loss: 1.59165e+01 | train acc: 0.3016 | valid acc: 0.3095 | test acc: 0.3023 | patience: 0\n",
      "epoch:       10 | train loss: 1.59305e+01 | valid loss: 1.59226e+01 | train acc: 0.3175 | valid acc: 0.2381 | test acc: 0.3488 | patience: 10\n",
      "epoch:       20 | train loss: 1.58255e+01 | valid loss: 1.58300e+01 | train acc: 0.3175 | valid acc: 0.2381 | test acc: 0.3488 | patience: 1\n",
      "epoch:       30 | train loss: 1.57163e+01 | valid loss: 1.57201e+01 | train acc: 0.3175 | valid acc: 0.2381 | test acc: 0.3488 | patience: 0\n",
      "epoch:       40 | train loss: 1.56264e+01 | valid loss: 1.56080e+01 | train acc: 0.3175 | valid acc: 0.2381 | test acc: 0.3488 | patience: 0\n",
      "epoch:       50 | train loss: 1.55453e+01 | valid loss: 1.55076e+01 | train acc: 0.3175 | valid acc: 0.2381 | test acc: 0.3488 | patience: 0\n",
      "epoch:       60 | train loss: 1.54409e+01 | valid loss: 1.54459e+01 | train acc: 0.3175 | valid acc: 0.2381 | test acc: 0.3488 | patience: 4\n",
      "epoch:       70 | train loss: 1.53122e+01 | valid loss: 1.52975e+01 | train acc: 0.3254 | valid acc: 0.2381 | test acc: 0.3488 | patience: 0\n",
      "epoch:       80 | train loss: 1.52078e+01 | valid loss: 1.52041e+01 | train acc: 0.3254 | valid acc: 0.2143 | test acc: 0.3488 | patience: 0\n",
      "epoch:       90 | train loss: 1.51121e+01 | valid loss: 1.50745e+01 | train acc: 0.3254 | valid acc: 0.2381 | test acc: 0.3488 | patience: 0\n",
      "epoch:      100 | train loss: 1.49493e+01 | valid loss: 1.49463e+01 | train acc: 0.3968 | valid acc: 0.2857 | test acc: 0.3256 | patience: 0\n",
      "epoch:      110 | train loss: 1.47304e+01 | valid loss: 1.47324e+01 | train acc: 0.4206 | valid acc: 0.3333 | test acc: 0.3953 | patience: 0\n",
      "epoch:      120 | train loss: 1.44306e+01 | valid loss: 1.44535e+01 | train acc: 0.4127 | valid acc: 0.3333 | test acc: 0.4651 | patience: 0\n",
      "epoch:      130 | train loss: 1.39776e+01 | valid loss: 1.39421e+01 | train acc: 0.4127 | valid acc: 0.3095 | test acc: 0.4651 | patience: 0\n",
      "epoch:      140 | train loss: 1.36630e+01 | valid loss: 1.36421e+01 | train acc: 0.3492 | valid acc: 0.2381 | test acc: 0.3953 | patience: 1\n",
      "epoch:      150 | train loss: 1.35163e+01 | valid loss: 1.34854e+01 | train acc: 0.3730 | valid acc: 0.4524 | test acc: 0.3488 | patience: 4\n",
      "epoch:      160 | train loss: 1.29385e+01 | valid loss: 1.28442e+01 | train acc: 0.3730 | valid acc: 0.3810 | test acc: 0.3488 | patience: 0\n",
      "epoch:      170 | train loss: 1.22900e+01 | valid loss: 1.22253e+01 | train acc: 0.2063 | valid acc: 0.0952 | test acc: 0.1395 | patience: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/haibinzhao/Desktop/TECO/17_SNN/Code/baselines/test.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/haibinzhao/Desktop/TECO/17_SNN/Code/baselines/test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_nn \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39;49mtraining_snn(model, loss_fn, optimizer, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
      "File \u001b[0;32m~/Desktop/TECO/17_SNN/Code/baselines/training.py:67\u001b[0m, in \u001b[0;36mtraining_snn\u001b[0;34m(nn, loss_fn, optimizer, X_train, y_train, X_valid, y_valid, X_test, y_test)\u001b[0m\n\u001b[1;32m     64\u001b[0m     loss_valid \u001b[39m=\u001b[39m loss_fn(y_pred_valid, y_valid)\n\u001b[1;32m     65\u001b[0m     acc_valid \u001b[39m=\u001b[39m (nn\u001b[39m.\u001b[39mspikes\u001b[39m.\u001b[39msum(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m y_valid)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\n\u001b[0;32m---> 67\u001b[0m     y_pred_test \u001b[39m=\u001b[39m nn(X_test)\n\u001b[1;32m     68\u001b[0m     acc_test \u001b[39m=\u001b[39m (nn\u001b[39m.\u001b[39mspikes\u001b[39m.\u001b[39msum(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m y_test)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m loss_valid \u001b[39m<\u001b[39m best_loss:\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/haibinzhao/Desktop/TECO/17_SNN/Code/baselines/test.ipynb Cell 7\u001b[0m in \u001b[0;36mSNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haibinzhao/Desktop/TECO/17_SNN/Code/baselines/test.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m spk2, mem2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlif2(curl1, mem2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haibinzhao/Desktop/TECO/17_SNN/Code/baselines/test.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m curl2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(spk2)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/haibinzhao/Desktop/TECO/17_SNN/Code/baselines/test.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m spk3, mem3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlif3(curl2, mem3)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haibinzhao/Desktop/TECO/17_SNN/Code/baselines/test.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m spk_rec\u001b[39m.\u001b[39mappend(spk3)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haibinzhao/Desktop/TECO/17_SNN/Code/baselines/test.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m mem_rec\u001b[39m.\u001b[39mappend(mem3)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/snntorch/_neurons/leaky.py:170\u001b[0m, in \u001b[0;36mLeaky.forward\u001b[0;34m(self, input_, mem)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_hidden:\n\u001b[1;32m    169\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmem_reset(mem)\n\u001b[0;32m--> 170\u001b[0m     mem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_state_function(input_, mem)\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_quant:\n\u001b[1;32m    173\u001b[0m         mem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_quant(mem)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_nn = T.training_snn(model, loss_fn, optimizer, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
