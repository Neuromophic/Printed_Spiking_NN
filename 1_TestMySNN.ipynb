{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N_class': 2,\n",
      " 'N_feature': 6,\n",
      " 'N_test': 25,\n",
      " 'N_time': 100,\n",
      " 'N_train': 70,\n",
      " 'N_valid': 23,\n",
      " 'dataname': 'acuteinflammation'}\n",
      "Training network on device: cpu.\n",
      "Training setup: model_SNN_data_acuteinflammation_seed_00.model.\n",
      "| Epoch:      0 | Train loss: 2.0324e+00 | Valid loss: 2.6567e-01 | Train acc: 0.5286 | Valid acc: 0.6087 | patience:   0 | lr: 0.1 | Epoch time: 0.4 | Power: 0.00e+00 |\n",
      "| Epoch:      1 | Train loss: 2.5591e-01 | Valid loss: 8.4449e-01 | Train acc: 0.5286 | Valid acc: 0.9565 | patience:   1 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      2 | Train loss: 7.6835e-01 | Valid loss: 4.1404e-01 | Train acc: 0.9571 | Valid acc: 0.8696 | patience:   2 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      3 | Train loss: 3.9333e-01 | Valid loss: 3.8514e-01 | Train acc: 0.8429 | Valid acc: 0.8261 | patience:   3 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      4 | Train loss: 3.8293e-01 | Valid loss: 3.9119e-01 | Train acc: 0.7429 | Valid acc: 0.7826 | patience:   4 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      5 | Train loss: 3.9485e-01 | Valid loss: 4.0471e-01 | Train acc: 0.6000 | Valid acc: 0.7391 | patience:   5 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      6 | Train loss: 4.2495e-01 | Valid loss: 4.0285e-01 | Train acc: 0.5857 | Valid acc: 0.7391 | patience:   6 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      7 | Train loss: 4.1865e-01 | Valid loss: 4.1553e-01 | Train acc: 0.5857 | Valid acc: 0.6957 | patience:   7 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      8 | Train loss: 4.0501e-01 | Valid loss: 4.2249e-01 | Train acc: 0.6000 | Valid acc: 0.7826 | patience:   8 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      9 | Train loss: 4.0257e-01 | Valid loss: 4.1713e-01 | Train acc: 0.7000 | Valid acc: 0.8261 | patience:   9 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:     10 | Train loss: 4.0047e-01 | Valid loss: 3.9275e-01 | Train acc: 0.7714 | Valid acc: 0.8696 | patience:  10 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#SBATCH --job-name=SNN\n",
    "#SBATCH --error=%x.%j.err\n",
    "#SBATCH --output=%x.%j.out\n",
    "#SBATCH --mail-user=hzhao@teco.edu\n",
    "#SBATCH --export=ALL\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --partition=sdil\n",
    "#SBATCH --gres=gpu:1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), 'utils'))\n",
    "from configuration import *\n",
    "import torch\n",
    "import pprint\n",
    "import BaselineSNN as B\n",
    "from utils import *\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.projectname = 'test1111'\n",
    "args.DATASET = 0\n",
    "args.DEVICE = 'cpu'\n",
    "args.metric = 'nominal_snn'\n",
    "\n",
    "\n",
    "train_loader, datainfo = GetDataLoader(args, 'train')\n",
    "valid_loader, datainfo = GetDataLoader(args, 'valid')\n",
    "test_loader, datainfo = GetDataLoader(args, 'test')\n",
    "pprint.pprint(datainfo)\n",
    "\n",
    "for seed in range(10):\n",
    "    args.SEED = seed\n",
    "    args = FormulateArgs(args)\n",
    "\n",
    "    print(f'Training network on device: {args.DEVICE}.')\n",
    "    MakeFolder(args)\n",
    "    \n",
    "    SetSeed(args.SEED)\n",
    "    \n",
    "    setup = f\"model_SNN_data_{datainfo['dataname']}_seed_{args.SEED:02d}.model\"\n",
    "    print(f'Training setup: {setup}.')\n",
    "\n",
    "    msglogger = GetMessageLogger(args, setup)\n",
    "    msglogger.info(f'Training network on device: {args.DEVICE}.')\n",
    "    msglogger.info(f'Training setup: {setup}.')\n",
    "    msglogger.info(datainfo)\n",
    "    \n",
    "\n",
    "    if os.path.isfile(f'{args.savepath}/{setup}'):\n",
    "            print(f'{setup} exists, skip this training.')\n",
    "            msglogger.info('Training was already finished.')\n",
    "    else:\n",
    "        topology = [datainfo['N_feature']] + args.hidden + [datainfo['N_class']]\n",
    "        msglogger.info(f'Topology of the network: {topology}.')\n",
    "\n",
    "        snn = B.SpikingNeuralNetwork(args, topology).to(args.DEVICE)\n",
    "\n",
    "        lossfunction = B.SNNLoss().to(args.DEVICE)\n",
    "        optimizer = torch.optim.Adam(snn.GetParam(), lr=args.LR)\n",
    "\n",
    "        if args.PROGRESSIVE:\n",
    "            snn, best = train_pnn_progressive(snn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "        else:\n",
    "            snn, best = train_pnn(pnn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "\n",
    "        if best:\n",
    "            if not os.path.exists(f'{args.savepath}/'):\n",
    "                os.makedirs(f'{args.savepath}/')\n",
    "            torch.save(snn, f'{args.savepath}/{setup}')\n",
    "            msglogger.info('Training if finished.')\n",
    "        else:\n",
    "            msglogger.warning('Time out, further training is necessary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network on device: cpu.\n",
      "{'N_class': 2,\n",
      " 'N_feature': 6,\n",
      " 'N_test': 25,\n",
      " 'N_time': 100,\n",
      " 'N_train': 70,\n",
      " 'N_valid': 23,\n",
      " 'dataname': 'acuteinflammation'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Training network on device: {args.DEVICE}.')\n",
    "MakeFolder(args)\n",
    "\n",
    "train_loader, datainfo = GetDataLoader(args, 'train')\n",
    "valid_loader, datainfo = GetDataLoader(args, 'valid')\n",
    "test_loader, datainfo = GetDataLoader(args, 'test')\n",
    "pprint.pprint(datainfo)\n",
    "\n",
    "SetSeed(args.SEED)\n",
    "\n",
    "setup = f\"model_SNN_data_{datainfo['dataname']}_seed_{args.SEED:02d}.model\"\n",
    "print(f'Training setup: {setup}.')\n",
    "\n",
    "msglogger = GetMessageLogger(args, setup)\n",
    "msglogger.info(f'Training network on device: {args.DEVICE}.')\n",
    "msglogger.info(f'Training setup: {setup}.')\n",
    "msglogger.info(datainfo)\n",
    "\n",
    "if os.path.isfile(f'{args.savepath}/{setup}'):\n",
    "        print(f'{setup} exists, skip this training.')\n",
    "        msglogger.info('Training was already finished.')\n",
    "else:\n",
    "    topology = [datainfo['N_feature']] + args.hidden + [datainfo['N_class']]\n",
    "    msglogger.info(f'Topology of the network: {topology}.')\n",
    "    \n",
    "    snn = B.SpikingNeuralNetwork(args, topology).to(args.DEVICE)\n",
    "    \n",
    "    lossfunction = B.SNNLoss().to(args.DEVICE)\n",
    "    optimizer = torch.optim.Adam(snn.GetParam(), lr=args.LR)\n",
    "    \n",
    "    if args.PROGRESSIVE:\n",
    "        snn, best = train_pnn_progressive(snn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "    else:\n",
    "        snn, best = train_pnn(pnn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "\n",
    "    if best:\n",
    "        if not os.path.exists(f'{args.savepath}/'):\n",
    "            os.makedirs(f'{args.savepath}/')\n",
    "        torch.save(snn, f'{args.savepath}/{setup}')\n",
    "        msglogger.info('Training if finished.')\n",
    "    else:\n",
    "        msglogger.warning('Time out, further training is necessary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training setup: model_SNN_data_acuteinflammation_seed_00.model.\n"
     ]
    }
   ],
   "source": [
    "SetSeed(args.SEED)\n",
    "\n",
    "setup = f\"model_SNN_data_{datainfo['dataname']}_seed_{args.SEED:02d}.model\"\n",
    "print(f'Training setup: {setup}.')\n",
    "\n",
    "msglogger = GetMessageLogger(args, setup)\n",
    "msglogger.info(f'Training network on device: {args.DEVICE}.')\n",
    "msglogger.info(f'Training setup: {setup}.')\n",
    "msglogger.info(datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(f'{args.savepath}/{setup}'):\n",
    "        print(f'{setup} exists, skip this training.')\n",
    "        msglogger.info('Training was already finished.')\n",
    "else:\n",
    "    topology = [datainfo['N_feature']] + args.hidden + [datainfo['N_class']]\n",
    "    msglogger.info(f'Topology of the network: {topology}.')\n",
    "    \n",
    "    print()\n",
    "\n",
    "    snn = B.SpikingNeuralNetwork(args, topology).to(args.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lossfunction = B.SNNLoss().to(args.DEVICE)\n",
    "optimizer = torch.optim.Adam(snn.GetParam(), lr=args.LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:      0 | Train loss: 2.0324e+00 | Valid loss: 2.6567e-01 | Train acc: 0.5286 | Valid acc: 0.6087 | patience:   0 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      1 | Train loss: 2.5591e-01 | Valid loss: 8.4449e-01 | Train acc: 0.5286 | Valid acc: 0.9565 | patience:   1 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      2 | Train loss: 7.6835e-01 | Valid loss: 4.1404e-01 | Train acc: 0.9571 | Valid acc: 0.8696 | patience:   2 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      3 | Train loss: 3.9333e-01 | Valid loss: 3.8514e-01 | Train acc: 0.8429 | Valid acc: 0.8261 | patience:   3 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      4 | Train loss: 3.8293e-01 | Valid loss: 3.9119e-01 | Train acc: 0.7429 | Valid acc: 0.7826 | patience:   4 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      5 | Train loss: 3.9485e-01 | Valid loss: 4.0471e-01 | Train acc: 0.6000 | Valid acc: 0.7391 | patience:   5 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      6 | Train loss: 4.2495e-01 | Valid loss: 4.0285e-01 | Train acc: 0.5857 | Valid acc: 0.7391 | patience:   6 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n",
      "| Epoch:      7 | Train loss: 4.1865e-01 | Valid loss: 4.1553e-01 | Train acc: 0.5857 | Valid acc: 0.6957 | patience:   7 | lr: 0.1 | Epoch time: 0.3 | Power: 0.00e+00 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args.PROGRESSIVE:\n",
    "    snn, best = train_pnn_progressive(snn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "else:\n",
    "    snn, best = train_pnn(pnn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "\n",
    "if best:\n",
    "    if not os.path.exists(f'{args.savepath}/'):\n",
    "        os.makedirs(f'{args.savepath}/')\n",
    "    torch.save(snn, f'{args.savepath}/{setup}')\n",
    "    msglogger.info('Training if finished.')\n",
    "else:\n",
    "    msglogger.warning('Time out, further training is necessary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "c = 0\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(X_train[n,c,:]/10, label='input')\n",
    "plt.plot(spikes[n,c,:].detach().numpy(), label='spike')\n",
    "plt.plot(memories[n,c,:].detach().numpy(), label='memory')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmac = psnn.TemporalWeightedSum(N_channel, N_class)\n",
    "tmac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mactmac = tmac(spikes)\n",
    "mactmac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "topology = [N_channel, 3, N_class]\n",
    "snn = psnn.SpikingNeuralNetwork(topology, beta, threshold)\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.ResetOutput(False, 1)\n",
    "input = snn.model[0](X_train)\n",
    "spikes,memories = snn.model[1](input)\n",
    "n = 0\n",
    "c = 0\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(input[n,c,:].detach().numpy(), label='input')\n",
    "plt.plot(spikes[n,c,:].detach().numpy(), label='spike')\n",
    "plt.plot(memories[n,c,:].detach().numpy(), label='memory')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "topology = [N_channel, 3, N_class]\n",
    "snn = psnn.SpikingNeuralNetwork(topology, beta=torch.zeros(1), threshold=torch.ones(1))\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=0.1)\n",
    "loss_fn = psnn.SNNLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    y_pred_train = snn(X_train)\n",
    "    loss_train = loss_fn(y_pred_train, y_train)\n",
    "    acc_train = (y_pred_train.sum(2).argmax(dim=1) == y_train).float().mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    print(f'epoch: {epoch:-8d} | train loss: {loss_train:.5e} | train acc: {acc_train:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.randperm(N_train)[:100]\n",
    "\n",
    "X_visual = X_train[idx,:,:]\n",
    "y_visual = y_train[idx]\n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    plt.plot(X_visual[i,0,:].detach().numpy(), label=f'{y_visual[i]}')\n",
    "    plt.axis('off')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N_class': 2,\n",
      " 'N_feature': 6,\n",
      " 'N_test': 25,\n",
      " 'N_time': 100,\n",
      " 'N_train': 70,\n",
      " 'N_valid': 23,\n",
      " 'dataname': 'acuteinflammation'}\n",
      "{'N_class': 3,\n",
      " 'N_feature': 4,\n",
      " 'N_test': 79,\n",
      " 'N_time': 100,\n",
      " 'N_train': 373,\n",
      " 'N_valid': 124,\n",
      " 'dataname': 'balancescale'}\n",
      "{'N_class': 2,\n",
      " 'N_feature': 9,\n",
      " 'N_test': 79,\n",
      " 'N_time': 100,\n",
      " 'N_train': 397,\n",
      " 'N_valid': 127,\n",
      " 'dataname': 'breastcancerwisc'}\n",
      "{'N_class': 3,\n",
      " 'N_feature': 21,\n",
      " 'N_test': 79,\n",
      " 'N_time': 100,\n",
      " 'N_train': 397,\n",
      " 'N_valid': 127,\n",
      " 'dataname': 'cardiotocography3clases'}\n",
      "{'N_class': 3,\n",
      " 'N_feature': 8,\n",
      " 'N_test': 79,\n",
      " 'N_time': 100,\n",
      " 'N_train': 397,\n",
      " 'N_valid': 127,\n",
      " 'dataname': 'energyy1'}\n",
      "{'N_class': 3,\n",
      " 'N_feature': 8,\n",
      " 'N_test': 79,\n",
      " 'N_time': 100,\n",
      " 'N_train': 397,\n",
      " 'N_valid': 127,\n",
      " 'dataname': 'energyy2'}\n",
      "{'N_class': 3,\n",
      " 'N_feature': 4,\n",
      " 'N_test': 31,\n",
      " 'N_time': 100,\n",
      " 'N_train': 88,\n",
      " 'N_valid': 29,\n",
      " 'dataname': 'iris'}\n",
      "{'N_class': 2,\n",
      " 'N_feature': 5,\n",
      " 'N_test': 79,\n",
      " 'N_time': 100,\n",
      " 'N_train': 397,\n",
      " 'N_valid': 127,\n",
      " 'dataname': 'mammographic'}\n",
      "{'N_class': 10,\n",
      " 'N_feature': 16,\n",
      " 'N_test': 79,\n",
      " 'N_time': 100,\n",
      " 'N_train': 397,\n",
      " 'N_valid': 127,\n",
      " 'dataname': 'pendigits'}\n",
      "{'N_class': 3,\n",
      " 'N_feature': 7,\n",
      " 'N_test': 43,\n",
      " 'N_time': 100,\n",
      " 'N_train': 124,\n",
      " 'N_valid': 41,\n",
      " 'dataname': 'seeds'}\n",
      "{'N_class': 2,\n",
      " 'N_feature': 9,\n",
      " 'N_test': 79,\n",
      " 'N_time': 100,\n",
      " 'N_train': 397,\n",
      " 'N_valid': 127,\n",
      " 'dataname': 'tictactoe'}\n",
      "{'N_class': 2,\n",
      " 'N_feature': 6,\n",
      " 'N_test': 63,\n",
      " 'N_time': 100,\n",
      " 'N_train': 184,\n",
      " 'N_valid': 61,\n",
      " 'dataname': 'vertebralcolumn2clases'}\n",
      "{'N_class': 3,\n",
      " 'N_feature': 6,\n",
      " 'N_test': 63,\n",
      " 'N_time': 100,\n",
      " 'N_train': 184,\n",
      " 'N_valid': 61,\n",
      " 'dataname': 'vertebralcolumn3clases'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), 'utils'))\n",
    "from configuration import *\n",
    "import torch\n",
    "import pprint\n",
    "import BaselineSNN as B\n",
    "from utils import *\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.projectname = 'test1111'\n",
    "args.DATASET = 0\n",
    "args.DEVICE = 'cpu'\n",
    "args.metric = 'nominal_snn'\n",
    "\n",
    "for ds in range(13):\n",
    "    args.DATASET = ds\n",
    "    train_loader, datainfo = GetDataLoader(args, 'train')\n",
    "    valid_loader, datainfo = GetDataLoader(args, 'valid')\n",
    "    test_loader, datainfo = GetDataLoader(args, 'test')\n",
    "    pprint.pprint(datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pNN",
   "language": "python",
   "name": "pnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
